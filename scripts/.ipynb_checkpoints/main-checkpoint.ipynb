{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bengali Handwritten-Character Classifiaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we've tried to implement a deep learning model on 'BanglaLekha-Isolated' dataset which contains more than 100K handwritten images of Benagli Alphabets. It is divided into 84 classes. All the pre-processing and model architecture code has been written in other python files as different modules stored in the same directory, and in this part we will import & work with that modules/libaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the Global libarires required...\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing all the Local libaries required...\n",
    "from preprocessing import data_processing\n",
    "from model_architecture import NetV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing of the Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing some of the Variables and calling the already written local functions\n",
    "\n",
    "TRAINING_DIR = \".\\..\\dataset\\BanglaLekha-Isolated\\Images\"\n",
    "batch_size = 128\n",
    "preprocess = data_processing(TRAINING_DIR, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 119639 images belonging to 84 classes.\n",
      "Found 119639 images belonging to 84 classes.\n"
     ]
    }
   ],
   "source": [
    "# Spilliting the dataset into training and valiidation dataset using the local functions\n",
    "\n",
    "train_generator = preprocess.train_dataset()\n",
    "validation_generator = preprocess.train_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling NetV1() from already written model_architecture python file\n",
    "\n",
    "architecture = NetV1(input_shape = (32, 32, 1), output = 84)\n",
    "model = architecture.make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2D_1 (Conv2D)              (None, 32, 32, 32)   832         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2D_2 (Conv2D)              (None, 32, 32, 32)   25632       ['conv2D_1[0][0]']               \n",
      "                                                                                                  \n",
      " first_batchNorm_layer (BatchNo  (None, 32, 32, 32)  128         ['conv2D_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 16, 16, 32)   0           ['first_batchNorm_layer[0][0]']  \n",
      "                                                                                                  \n",
      " first_branch_0_conv2D_1 (Conv2  (None, 16, 16, 128)  4224       ['max_pooling2d[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " first_branch_1_conv2D_1 (Conv2  (None, 16, 16, 128)  4224       ['max_pooling2d[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " first_branch_3_MaxPool_1 (MaxP  (None, 16, 16, 32)  0           ['max_pooling2d[0][0]']          \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " first_branch_0_conv2D_2 (Conv2  (None, 16, 16, 128)  409728     ['first_branch_0_conv2D_1[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " first_branch_1_conv2D_2 (Conv2  (None, 16, 16, 128)  147584     ['first_branch_1_conv2D_1[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " first_branch_2_conv2D (Conv2D)  (None, 16, 16, 128)  4224       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " first_branch_3_Convolution (Co  (None, 16, 16, 64)  2112        ['first_branch_3_MaxPool_1[0][0]'\n",
      " nv2D)                                                           ]                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 16, 448)  0           ['first_branch_0_conv2D_2[0][0]',\n",
      "                                                                  'first_branch_1_conv2D_2[0][0]',\n",
      "                                                                  'first_branch_2_conv2D[0][0]',  \n",
      "                                                                  'first_branch_3_Convolution[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16, 16, 448)  0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2D_3 (Conv2D)              (None, 16, 16, 256)  1032448     ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 256)   0           ['conv2D_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2D_4 (Conv2D)              (None, 8, 8, 256)    590080      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " second_batchNorm_layer (BatchN  (None, 8, 8, 256)   1024        ['conv2D_4[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 8, 8, 256)    0           ['second_batchNorm_layer[0][0]'] \n",
      "                                                                                                  \n",
      " conv2D_5 (Conv2D)              (None, 8, 8, 512)    1180160     ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 512)   0           ['conv2D_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2D_6 (Conv2D)              (None, 4, 4, 512)    2359808     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " third_batchNorm_layer (BatchNo  (None, 4, 4, 512)   2048        ['conv2D_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 4, 4, 512)    0           ['third_batchNorm_layer[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 512)   0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " firstDenseLayer (Dense)        (None, 1024)         2098176     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " SecondDenseLayer (Dense)       (None, 512)          524800      ['firstDenseLayer[0][0]']        \n",
      "                                                                                                  \n",
      " FirstDropOutLayer (Dropout)    (None, 512)          0           ['SecondDenseLayer[0][0]']       \n",
      "                                                                                                  \n",
      " ThirdDenseLayer (Dense)        (None, 256)          131328      ['FirstDropOutLayer[0][0]']      \n",
      "                                                                                                  \n",
      " FourthDenseLayer (Dense)       (None, 128)          32896       ['ThirdDenseLayer[0][0]']        \n",
      "                                                                                                  \n",
      " FinalSoftmaxLayer (Dense)      (None, 84)           10836       ['FourthDenseLayer[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,562,292\n",
      "Trainable params: 8,560,692\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Initializing the learning rates, loss functions, optimizers and all.\n",
    "\n",
    "learning_rate = 0.0001\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'], \n",
    "              optimizer = Adam(learning_rate = learning_rate))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model with image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "934/934 [==============================] - 3586s 4s/step - loss: 3.5849 - accuracy: 0.5263 - val_loss: 2.1036 - val_accuracy: 0.8098\n",
      "Epoch 2/5\n",
      "934/934 [==============================] - 3718s 4s/step - loss: 1.9050 - accuracy: 0.8249 - val_loss: 1.5896 - val_accuracy: 0.8788\n",
      "Epoch 3/5\n",
      "934/934 [==============================] - 3576s 4s/step - loss: 1.5098 - accuracy: 0.8720 - val_loss: 1.2819 - val_accuracy: 0.9090\n",
      "Epoch 4/5\n",
      "934/934 [==============================] - 3459s 4s/step - loss: 1.2460 - accuracy: 0.8951 - val_loss: 1.0865 - val_accuracy: 0.9160\n",
      "Epoch 5/5\n",
      "934/934 [==============================] - 4327s 5s/step - loss: 1.0339 - accuracy: 0.9115 - val_loss: 0.8781 - val_accuracy: 0.9339\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f32d51405f04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     validation_steps = validation_generator.samples // batch_size)\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"my_model3.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrained_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "# \n",
    "trained_model = model.fit(train_generator,\n",
    "                    epochs = 5,\n",
    "                    steps_per_epoch = train_generator.samples // batch_size,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = validation_generator.samples // batch_size)\n",
    "\n",
    "# Saving the model for further use\n",
    "model.save(\"my_model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [3.5848629474639893,\n",
       "  1.9049779176712036,\n",
       "  1.5097893476486206,\n",
       "  1.2459746599197388,\n",
       "  1.033942699432373],\n",
       " 'accuracy': [0.526252806186676,\n",
       "  0.8248612880706787,\n",
       "  0.8720201253890991,\n",
       "  0.8951226472854614,\n",
       "  0.9115394949913025],\n",
       " 'val_loss': [2.103621244430542,\n",
       "  1.5896368026733398,\n",
       "  1.2818880081176758,\n",
       "  1.0865086317062378,\n",
       "  0.8780979514122009],\n",
       " 'val_accuracy': [0.809814989566803,\n",
       "  0.8788393139839172,\n",
       "  0.9089601039886475,\n",
       "  0.9160030484199524,\n",
       "  0.9338948726654053]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting all the statistics of the 5 epochs\n",
    "trained_model.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the statistics returned by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the stats files in (.json)\n",
    "import json\n",
    "\n",
    "with open(\"loss_scores\",\"w\") as fp:\n",
    "    json.dump(trained_model.history['loss'], fp)\n",
    "    fp.close()\n",
    "    \n",
    "with open(\"accuracy_scores\",\"w\") as fp:\n",
    "    json.dump(trained_model.history['accuracy'], fp)\n",
    "    fp.close()\n",
    "\n",
    "with open(\"val_loss_scores\",\"w\") as fp:\n",
    "    json.dump(trained_model.history['val_loss'], fp)\n",
    "    fp.close()\n",
    "    \n",
    "with open(\"val_accuracy_scores\",\"w\") as fp:\n",
    "    json.dump(trained_model.history['val_accuracy'], fp)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_true = validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_predict = model.evaluate(validation_generator)\n",
    "val_predict = model.predict(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
