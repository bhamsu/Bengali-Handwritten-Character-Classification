{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the pre-trained model on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the Global libarires required...\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array, ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the pre-trained model from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "model = tf.keras.models.load_model(\"my_model3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1840edbf430>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the image\n",
    "my_image = tf.keras.utils.load_img(\".\\\\dataset\\\\BanglaLekha-Isolated\\\\Images\\\\55\\\\01_0001_0_13_0916_1908_55.png\",\n",
    "                    target_size = (32, 32),\n",
    "                    color_mode = 'grayscale')\n",
    "plt.imshow(my_image, cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing the image data to feed into the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# my_image = img_to_array(my_image)\n",
    "# my_image = tf.convert_to_tensor(my_image)\n",
    "# my_image = tf.image.rgb_to_grayscale(my_image)\n",
    "\n",
    "my_image = (np.expand_dims(my_image, 0))\n",
    "print(my_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feeding the processed image date into pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 9.9998450e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 8.2421653e-17 1.5533289e-05 5.1034937e-36 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], shape=(84,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Prediction and the predicted values\n",
    "predictions = model(my_image)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "# Finding out which class the image belongs to..\n",
    "predictions1 = [float(predictions[0][i]) for i in range(0,len(predictions[0]))]\n",
    "for i in range(0,len(predictions1)):\n",
    "    if predictions1[i] == max(predictions1):\n",
    "        print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
